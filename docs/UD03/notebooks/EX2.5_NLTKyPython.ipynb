{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "afcea688-88b6-46ea-a926-e12770c2aaa5",
      "metadata": {
        "id": "afcea688-88b6-46ea-a926-e12770c2aaa5"
      },
      "source": [
        "# Ejercicios UD03_02.5"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a2f1713",
      "metadata": {
        "id": "9a2f1713"
      },
      "source": [
        "## Uso de NLTK y Python\n",
        "\n",
        "* *Referencias:*\n",
        "    * *http://www.nltk.org/*\n",
        "    * *http://www.python.org/*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7bd2f7bd-9dbf-4e6b-a44c-b28e50be76eb",
      "metadata": {
        "id": "7bd2f7bd-9dbf-4e6b-a44c-b28e50be76eb"
      },
      "source": [
        "### a)Procesamiento del corpus cess_esp anotado con información morfosintáctica.\n",
        "\n",
        "* Dividir el corpus en dos partes: training (el 90% de las primeras frases) y de test (el 10% restante)\n",
        "* Reducir el conjunto de etiquetas morfosintácticas del corpus (289) a un conjunto reducido(67). Para ello, considerar las etiquetas de longitud =2 salvo los verbos (v) y los signos de puntuación (F) que pueden ser de tres. También pueden existir etiquetas de longitud =1. Eliminar también las tuplas vacias, por ejemplo: (u'*0*', u'sn'), son tuplas que el primer elemento tiene el valor '*0*'.\n",
        "\n",
        ">Nota: para entender el significado de las etiquetas se puede consultar el siguiente enlace: https://freeling-user-manual.readthedocs.io/en/latest/tagsets/tagset-es/\n",
        "\n",
        "Ejemplo de lo que se pide:\n",
        "* original\n",
        "```\n",
        "[[('El', 'da0ms0'), ('grupo', 'ncms000'), ('estatal', 'aq0cs0'), ('Electricité_de_France', 'np00000'), ('-Fpa-', 'Fpa'), ('EDF', 'np00000'), ('-Fpt-', 'Fpt'), ('anunció', 'vmis3s0'), ('hoy', 'rg'), (',', 'Fc'), ('jueves', 'W'), (',', 'Fc'), ('la', 'da0fs0'), ('compra', 'ncfs000'), ('del', 'spcms'), ('51_por_ciento', 'Zp'), ('de', 'sps00'), ('la', 'da0fs0'), ('empresa', 'ncfs000'), ('mexicana', 'aq0fs0'), ('Electricidad_Águila_de_Altamira', 'np00000'), ('-Fpa-', 'Fpa'), ('EAA', 'np00000'), ('-Fpt-', 'Fpt'), (',', 'Fc'), ('creada', 'aq0fsp'), ('por', 'sps00'), ('el', 'da0ms0'), ('japonés', 'aq0ms0'), ('Mitsubishi_Corporation', 'np00000'), ('para', 'sps00'), ('poner_en_marcha', 'vmn0000'), ('una', 'di0fs0'), ('central', 'ncfs000'), ('de', 'sps00'), ('gas', 'ncms000'), ('de', 'sps00'), ('495', 'Z'), ('megavatios', 'ncmp000'), ('.', 'Fp')], [('Una', 'di0fs0'), ('portavoz', 'nccs000'), ('de', 'sps00'), ('EDF', 'np00000'), ('explicó', 'vmis3s0'), ('a', 'sps00'), ('EFE', 'np00000'), ('que', 'cs'), ('el', 'da0ms0'), ('proyecto', 'ncms000'), ('para', 'sps00'), ('la', 'da0fs0'), ('construcción', 'ncfs000'), ('de', 'sps00'), ('Altamira_2', 'np00000'), (',', 'Fc'), ('al', 'spcms'), ('norte', 'ncms000'), ('de', 'sps00'), ('Tampico', 'np00000'), (',', 'Fc'), ('prevé', 'vmm02s0'), ('la', 'da0fs0'), ('utilización', 'ncfs000'), ('de', 'sps00'), ('gas', 'ncms000'), ('natural', 'aq0cs0'), ('como', 'cs'), ('combustible', 'ncms000'), ('principal', 'aq0cs0'), ('en', 'sps00'), ('una', 'di0fs0'), ('central', 'ncfs000'), ('de', 'sps00'), ('ciclo', 'ncms000'), ('combinado', 'aq0msp'), ('que', 'pr0cn000'), ('debe', 'vmip3s0'), ('empezar', 'vmn0000'), ('a', 'sps00'), ('funcionar', 'vmn0000'), ('en', 'sps00'), ('mayo_del_2002', 'W'), ('.', 'Fp')]]\n",
        "```\n",
        "* nuevo\n",
        "```\n",
        "[[('El', 'da'), ('grupo', 'nc'), ('estatal', 'aq'), ('Electricité_de_France', 'np'), ('-Fpa-', 'fpa'), ('EDF', 'np'), ('-Fpt-', 'fpt'), ('anunció', 'vmi'), ('hoy', 'rg'), (',', 'fc'), ('jueves', 'w'), (',', 'fc'), ('la', 'da'), ('compra', 'nc'), ('del', 'sp'), ('51_por_ciento', 'zp'), ('de', 'sp'), ('la', 'da'), ('empresa', 'nc'), ('mexicana', 'aq'), ('Electricidad_Águila_de_Altamira', 'np'), ('-Fpa-', 'fpa'), ('EAA', 'np'), ('-Fpt-', 'fpt'), (',', 'fc'), ('creada', 'aq'), ('por', 'sp'), ('el', 'da'), ('japonés', 'aq'), ('Mitsubishi_Corporation', 'np'), ('para', 'sp'), ('poner_en_marcha', 'vmn'), ('una', 'di'), ('central', 'nc'), ('de', 'sp'), ('gas', 'nc'), ('de', 'sp'), ('495', 'z'), ('megavatios', 'nc'), ('.', 'fp')], [('Una', 'di'), ('portavoz', 'nc'), ('de', 'sp'), ('EDF', 'np'), ('explicó', 'vmi'), ('a', 'sp'), ('EFE', 'np'), ('que', 'cs'), ('el', 'da'), ('proyecto', 'nc'), ('para', 'sp'), ('la', 'da'), ('construcción', 'nc'), ('de', 'sp'), ('Altamira_2', 'np'), (',', 'fc'), ('al', 'sp'), ('norte', 'nc'), ('de', 'sp'), ('Tampico', 'np'), (',', 'fc'), ('prevé', 'vmm'), ('la', 'da'), ('utilización', 'nc'), ('de', 'sp'), ('gas', 'nc'), ('natural', 'aq'), ('como', 'cs'), ('combustible', 'nc'), ('principal', 'aq'), ('en', 'sp'), ('una', 'di'), ('central', 'nc'), ('de', 'sp'), ('ciclo', 'nc'), ('combinado', 'aq'), ('que', 'pr'), ('debe', 'vmi'), ('empezar', 'vmn'), ('a', 'sp'), ('funcionar', 'vmn'), ('en', 'sp'), ('mayo_del_2002', 'w'), ('.', 'fp')]]\n",
        "```\n",
        "* opcional:\n",
        "    * número de frases: 6030\n",
        "    * número de palabras: 192686\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "6bf51799-c2de-4f4d-b8bb-95dbd6ea2ebb",
      "metadata": {
        "id": "6bf51799-c2de-4f4d-b8bb-95dbd6ea2ebb"
      },
      "outputs": [],
      "source": [
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "1958cdd1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1958cdd1",
        "outputId": "65d29656-8c05-4166-d6df-6df60984f5e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]   Package cess_esp is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "#Descargar el corpus\n",
        "#1. ejecutar esta linea\n",
        "# nltk.download()\n",
        "#2. elegir la opción d) Download\n",
        "#3. escribir identificador del corpus que deseamos, en nuestro caso 'cess_esp', 'punkt'... o bien 'all'\n",
        "#4. q) quit\n",
        "\n",
        "nltk.download('cess_esp')\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab') # Necesario en versiones nuevas de NLTK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "fe24a7cb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fe24a7cb",
        "outputId": "3d30a234-a0e2-4f50-efdb-382c6eb945cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de sentencias: 6030\n",
            "Número de palabras: 192686\n",
            "\n",
            "--- 3 primeras frases originales ---\n",
            "[[('El', 'da0ms0'), ('grupo', 'ncms000'), ('estatal', 'aq0cs0'), ('Electricité_de_France', 'np00000'), ('-Fpa-', 'Fpa'), ('EDF', 'np00000'), ('-Fpt-', 'Fpt'), ('anunció', 'vmis3s0'), ('hoy', 'rg'), (',', 'Fc'), ('jueves', 'W'), (',', 'Fc'), ('la', 'da0fs0'), ('compra', 'ncfs000'), ('del', 'spcms'), ('51_por_ciento', 'Zp'), ('de', 'sps00'), ('la', 'da0fs0'), ('empresa', 'ncfs000'), ('mexicana', 'aq0fs0'), ('Electricidad_Águila_de_Altamira', 'np00000'), ('-Fpa-', 'Fpa'), ('EAA', 'np00000'), ('-Fpt-', 'Fpt'), (',', 'Fc'), ('creada', 'aq0fsp'), ('por', 'sps00'), ('el', 'da0ms0'), ('japonés', 'aq0ms0'), ('Mitsubishi_Corporation', 'np00000'), ('para', 'sps00'), ('poner_en_marcha', 'vmn0000'), ('una', 'di0fs0'), ('central', 'ncfs000'), ('de', 'sps00'), ('gas', 'ncms000'), ('de', 'sps00'), ('495', 'Z'), ('megavatios', 'ncmp000'), ('.', 'Fp')], [('Una', 'di0fs0'), ('portavoz', 'nccs000'), ('de', 'sps00'), ('EDF', 'np00000'), ('explicó', 'vmis3s0'), ('a', 'sps00'), ('EFE', 'np00000'), ('que', 'cs'), ('el', 'da0ms0'), ('proyecto', 'ncms000'), ('para', 'sps00'), ('la', 'da0fs0'), ('construcción', 'ncfs000'), ('de', 'sps00'), ('Altamira_2', 'np00000'), (',', 'Fc'), ('al', 'spcms'), ('norte', 'ncms000'), ('de', 'sps00'), ('Tampico', 'np00000'), (',', 'Fc'), ('prevé', 'vmm02s0'), ('la', 'da0fs0'), ('utilización', 'ncfs000'), ('de', 'sps00'), ('gas', 'ncms000'), ('natural', 'aq0cs0'), ('como', 'cs'), ('combustible', 'ncms000'), ('principal', 'aq0cs0'), ('en', 'sps00'), ('una', 'di0fs0'), ('central', 'ncfs000'), ('de', 'sps00'), ('ciclo', 'ncms000'), ('combinado', 'aq0msp'), ('que', 'pr0cn000'), ('debe', 'vmip3s0'), ('empezar', 'vmn0000'), ('a', 'sps00'), ('funcionar', 'vmn0000'), ('en', 'sps00'), ('mayo_del_2002', 'W'), ('.', 'Fp')], [('La', 'da0fs0'), ('electricidad', 'ncfs000'), ('producida', 'aq0fsp'), ('pasará', 'vmif3s0'), ('a', 'sps00'), ('la', 'da0fs0'), ('red', 'ncfs000'), ('eléctrica', 'aq0fs0'), ('pública', 'aq0fs0'), ('de', 'sps00'), ('México', 'np00000'), ('en_virtud_de', 'sps00'), ('un', 'di0ms0'), ('acuerdo', 'ncms000'), ('de', 'sps00'), ('venta', 'ncfs000'), ('de', 'sps00'), ('energía', 'ncfs000'), ('de', 'sps00'), ('EAA', 'np00000'), ('con', 'sps00'), ('la', 'da0fs0'), ('Comisión_Federal_de_Electricidad', 'np00000'), ('-Fpa-', 'Fpa'), ('CFE', 'np00000'), ('-Fpt-', 'Fpt'), ('por', 'sps00'), ('una', 'di0fs0'), ('duración', 'ncfs000'), ('de', 'sps00'), ('25', 'Z'), ('años', 'ncmp000'), ('.', 'Fp')]]\n",
            "\n",
            "--- 3 primeras frases procesadas (retic) ---\n",
            "[[('El', 'da'), ('grupo', 'nc'), ('estatal', 'aq'), ('Electricité_de_France', 'np'), ('-Fpa-', 'Fpa'), ('EDF', 'np'), ('-Fpt-', 'Fpt'), ('anunció', 'vmi'), ('hoy', 'rg'), (',', 'Fc'), ('jueves', 'W'), (',', 'Fc'), ('la', 'da'), ('compra', 'nc'), ('del', 'sp'), ('51_por_ciento', 'Zp'), ('de', 'sp'), ('la', 'da'), ('empresa', 'nc'), ('mexicana', 'aq'), ('Electricidad_Águila_de_Altamira', 'np'), ('-Fpa-', 'Fpa'), ('EAA', 'np'), ('-Fpt-', 'Fpt'), (',', 'Fc'), ('creada', 'aq'), ('por', 'sp'), ('el', 'da'), ('japonés', 'aq'), ('Mitsubishi_Corporation', 'np'), ('para', 'sp'), ('poner_en_marcha', 'vmn'), ('una', 'di'), ('central', 'nc'), ('de', 'sp'), ('gas', 'nc'), ('de', 'sp'), ('495', 'Z'), ('megavatios', 'nc'), ('.', 'Fp')], [('Una', 'di'), ('portavoz', 'nc'), ('de', 'sp'), ('EDF', 'np'), ('explicó', 'vmi'), ('a', 'sp'), ('EFE', 'np'), ('que', 'cs'), ('el', 'da'), ('proyecto', 'nc'), ('para', 'sp'), ('la', 'da'), ('construcción', 'nc'), ('de', 'sp'), ('Altamira_2', 'np'), (',', 'Fc'), ('al', 'sp'), ('norte', 'nc'), ('de', 'sp'), ('Tampico', 'np'), (',', 'Fc'), ('prevé', 'vmm'), ('la', 'da'), ('utilización', 'nc'), ('de', 'sp'), ('gas', 'nc'), ('natural', 'aq'), ('como', 'cs'), ('combustible', 'nc'), ('principal', 'aq'), ('en', 'sp'), ('una', 'di'), ('central', 'nc'), ('de', 'sp'), ('ciclo', 'nc'), ('combinado', 'aq'), ('que', 'pr'), ('debe', 'vmi'), ('empezar', 'vmn'), ('a', 'sp'), ('funcionar', 'vmn'), ('en', 'sp'), ('mayo_del_2002', 'W'), ('.', 'Fp')]]\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "from nltk.corpus import cess_esp\n",
        "\n",
        "corpus_sentences = list(cess_esp.tagged_sents())\n",
        "\n",
        "# --- OPCIONAL: Estadísticas ---\n",
        "num_sentencias = len(corpus_sentences)\n",
        "num_palabras = sum(len(oracion) for oracion in corpus_sentences)\n",
        "print(f\"Número de sentencias: {num_sentencias}\")\n",
        "print(f\"Número de palabras: {num_palabras}\")\n",
        "\n",
        "# --- Mostrar las 3 primeras frases originales ---\n",
        "print(\"\\n--- 3 primeras frases originales ---\")\n",
        "print(corpus_sentences[:3])\n",
        "\n",
        "# --- Escribir el corpus en un fichero (usando pickle) ---\n",
        "with open('corpus_cess.pkl', 'wb') as f:\n",
        "    pickle.dump(corpus_sentences, f)\n",
        "\n",
        "# --- Leer el corpus de un fichero y guardarlo en una lista ---\n",
        "with open('corpus_cess.pkl', 'rb') as f:\n",
        "    corpus_leido = pickle.load(f)\n",
        "\n",
        "# --- Función auxiliar getLabel ---\n",
        "def getLabel(tag):\n",
        "    # Si es verbo (v) o puntuación (F), mantenemos 3 caracteres\n",
        "    if tag.startswith('v') or tag.startswith('F'):\n",
        "        return tag[:3]\n",
        "    # Para el resto, reducimos a 2 caracteres\n",
        "    return tag[:2]\n",
        "\n",
        "# --- Procesar el corpus y guardar en retic ---\n",
        "retic = []\n",
        "\n",
        "for sentence in corpus_sentences:\n",
        "    new_sentence = []\n",
        "    for word, tag in sentence:\n",
        "        # Eliminamos nodos vacíos (*0*)\n",
        "        if word == '*0*':\n",
        "            continue\n",
        "        # Aplicamos la reducción de etiqueta\n",
        "        new_tag = getLabel(tag)\n",
        "        new_sentence.append((word, new_tag))\n",
        "\n",
        "    # Solo añadimos si la frase no ha quedado vacía\n",
        "    if new_sentence:\n",
        "        retic.append(new_sentence)\n",
        "\n",
        "# --- Mostrar las 3 primeras frases reducidas ---\n",
        "print(\"\\n--- 3 primeras frases procesadas (retic) ---\")\n",
        "print(retic[0:2])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35dee72f",
      "metadata": {
        "id": "35dee72f"
      },
      "source": [
        "### b) Uso de etiquetadores morfosintácticos (hmm o tnt).\n",
        "* Entrenar los etiquetadores con la partición de train previamente construida mostrar la precisión:\n",
        "\n",
        "```\n",
        "precisión hmm: 0.8784427571832664\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "5faa3b76",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5faa3b76",
        "outputId": "d9a08853-df3f-4d42-9bda-2cac0ae1f20e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entrenamiento: 5427 frases\n",
            "Test: 603 frases\n",
            "Entrenando HMM... (esto puede tardar unos segundos)\n",
            "Precisión hmm: 0.8784427571832664\n"
          ]
        }
      ],
      "source": [
        "from nltk.tag import HiddenMarkovModelTagger\n",
        "\n",
        "# Definimos la parte de corpus de entrenamiento (train 90%) y test (10%)\n",
        "cutoff = int(len(retic) * 0.90)\n",
        "train_data = retic[:cutoff]\n",
        "test_data = retic[cutoff:]\n",
        "\n",
        "print(f\"Entrenamiento: {len(train_data)} frases\")\n",
        "print(f\"Test: {len(test_data)} frases\")\n",
        "\n",
        "# Importamos el etiquetador HMM, lo entrenamos y mostramos su precisión\n",
        "print(\"Entrenando HMM... (esto puede tardar unos segundos)\")\n",
        "hmm_tagger = HiddenMarkovModelTagger.train(train_data)\n",
        "\n",
        "accuracy = hmm_tagger.accuracy(test_data)\n",
        "print(f\"Precisión hmm: {accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4bae1bb",
      "metadata": {
        "id": "f4bae1bb"
      },
      "source": [
        "### c) Etiquetar con dicho modelo el conjunto de test construido\n",
        "* Evaluar las prestaciones sobre el conjunto de test\n",
        "* Hacer una evaluación de las prestaciones de etiquetado usando todo el corpus (10-fold cross validation).\n",
        "\n",
        "```\n",
        "Media de la precisión de los 10 KFolds:  0.9580362988365326\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "3a63aade-6345-48f4-b559-d78f275ee306",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3a63aade-6345-48f4-b559-d78f275ee306",
        "outputId": "d0aab8d7-59f3-441c-c7c7-82df830e9160"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Versión de sklearn: 1.6.1\n"
          ]
        }
      ],
      "source": [
        "#importamos scikit-learn y mostramos la versión para comprobar que todo funcione bien.\n",
        "import sklearn\n",
        "sklearn.__version__\n",
        "print(f\"Versión de sklearn: {sklearn.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "1be17685-3072-4bc9-821d-0115b69f9713",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1be17685-3072-4bc9-821d-0115b69f9713",
        "outputId": "f373c04d-59bc-4a4d-ca6b-137266c2e545"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculando las prestaciones con 10-fold cross validation (Backoff activado)...\n",
            "Fold 1 Accuracy: 0.928317\n",
            "Fold 2 Accuracy: 0.923711\n",
            "Fold 3 Accuracy: 0.922830\n",
            "Fold 4 Accuracy: 0.925147\n",
            "Fold 5 Accuracy: 0.922863\n",
            "Fold 6 Accuracy: 0.878181\n",
            "Fold 7 Accuracy: 0.887891\n",
            "Fold 8 Accuracy: 0.891311\n",
            "Fold 9 Accuracy: 0.891165\n",
            "Fold 10 Accuracy: 0.878443\n",
            "------------------------------\n",
            "Media de la precisión de los 10 KFolds: 0.9049859134368964\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from nltk.tag import HiddenMarkovModelTagger, UnigramTagger, DefaultTagger\n",
        "import numpy as np\n",
        "\n",
        "# 1. Convertimos la lista 'retic' a un array de numpy para el split\n",
        "data = np.array(retic, dtype=object)\n",
        "\n",
        "# 2. Configuramos KFold de 10 splits sin shuffle\n",
        "kf = KFold(n_splits=10, shuffle=False)\n",
        "\n",
        "list_accuracy = []\n",
        "fold_n = 1\n",
        "\n",
        "print(\"Calculando las prestaciones con 10-fold cross validation (Backoff activado)...\")\n",
        "\n",
        "# 3. Bucle de validación cruzada\n",
        "for train_index, test_index in kf.split(data):\n",
        "    train_fold = data[train_index].tolist()\n",
        "    test_fold = data[test_index].tolist()\n",
        "\n",
        "    t0 = DefaultTagger('nc')\n",
        "    t1 = UnigramTagger(train_fold, backoff=t0)\n",
        "\n",
        "    # Paso 3: Entrenamos el HMM usando a t1 como respaldo (backoff)\n",
        "    model_fold = HiddenMarkovModelTagger.train(train_fold, backoff=t1)\n",
        "\n",
        "    # Evaluamos la precisión\n",
        "    acc = model_fold.accuracy(test_fold)\n",
        "    list_accuracy.append(acc)\n",
        "\n",
        "    print(f\"Fold {fold_n} Accuracy: {acc:.8f}\")\n",
        "    fold_n += 1\n",
        "\n",
        "# 4. Resultado final\n",
        "media_accuracy = np.mean(list_accuracy)\n",
        "print(\"-\" * 30)\n",
        "print(f\"Media de la precisión de los 10 KFolds: {media_accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93b6532c-73f5-4e76-94cd-009a8f52fde0",
      "metadata": {
        "id": "93b6532c-73f5-4e76-94cd-009a8f52fde0"
      },
      "source": [
        "### d) Tokenizar una frase y etiquetarla con el modelo entrenado previamente\n",
        "* Usar word_tokenize y tag del modelo usado (tnt, hmm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "26fab5ad-d2c8-4672-8453-f11d0739d32b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26fab5ad-d2c8-4672-8453-f11d0739d32b",
        "outputId": "516e2bf4-1428-452e-cfff-7a04696fec13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frase original: El niño juega con la pelota en la calle\n",
            "--------------------\n",
            "Etiquetado (Palabra, Categoría):\n",
            "[('El', 'da'), ('niño', 'nc'), ('juega', 'vmi'), ('con', 'sp'), ('la', 'da'), ('pelota', 'nc'), ('en', 'sp'), ('la', 'da'), ('calle', 'nc')]\n"
          ]
        }
      ],
      "source": [
        "# 1. Definimos la frase de ejemplo\n",
        "frase_ejemplo = \"El niño juega con la pelota en la calle\"\n",
        "\n",
        "# 2. Tokenizamos la frase\n",
        "tokens = nltk.word_tokenize(frase_ejemplo)\n",
        "\n",
        "# 3. Etiquetamos usando el modelo HMM entrenado anteriormente\n",
        "etiquetas = hmm_tagger.tag(tokens)\n",
        "\n",
        "# 4. Mostramos los resultados\n",
        "print(f\"Frase original: {frase_ejemplo}\")\n",
        "print(\"-\" * 20)\n",
        "print(\"Etiquetado (Palabra, Categoría):\")\n",
        "print(etiquetas)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "44b71a91-6d42-4673-ba93-face2dddef5a",
      "metadata": {
        "id": "44b71a91-6d42-4673-ba93-face2dddef5a"
      },
      "source": [
        "### e) De manera opcional puedes probar a cambiar el idioma, el corpus y ver si afecta mucho a la precisión de los modelos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "4fd6a8eb-9c0d-4f65-a173-ee5a78108ec3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fd6a8eb-9c0d-4f65-a173-ee5a78108ec3",
        "outputId": "f92787ed-a259-4b84-d79c-222cbed21589"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/treebank.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entrenando HMM con corpus en inglés (3522 frases)...\n",
            "\n",
            "--- COMPARATIVA DE IDIOMAS ---\n",
            "Precisión en Español (CESS_ESP): 0.8784\n",
            "Precisión en Inglés (Treebank): 0.9091\n",
            "\n",
            "Etiquetado ejemplo inglés: [('The', 'DT'), ('cat', 'NN'), ('is', 'VB'), ('on', 'IN'), ('the', 'DT'), ('table', 'NN')]\n"
          ]
        }
      ],
      "source": [
        "# 1. Descargamos el corpus en inglés 'treebank'\n",
        "nltk.download('treebank')\n",
        "from nltk.corpus import treebank\n",
        "\n",
        "# 2. Cargamos las frases etiquetadas en inglés\n",
        "english_sentences = list(treebank.tagged_sents())\n",
        "\n",
        "# 3. Procesamos las etiquetas (aquí no hace falta reducir tanto como en español)\n",
        "# pero eliminamos nodos vacíos si los hubiera\n",
        "english_corpus = []\n",
        "for sentence in english_sentences:\n",
        "    new_sentence = [(word, tag[:2]) for word, tag in sentence if word != '-NONE-']\n",
        "    if new_sentence:\n",
        "        english_corpus.append(new_sentence)\n",
        "\n",
        "# 4. Dividimos en Train y Test (90% - 10%)\n",
        "cutoff_en = int(len(english_corpus) * 0.90)\n",
        "train_en = english_corpus[:cutoff_en]\n",
        "test_en = english_corpus[cutoff_en:]\n",
        "\n",
        "# 5. Entrenamos el modelo HMM con el corpus inglés\n",
        "print(f\"Entrenando HMM con corpus en inglés ({len(train_en)} frases)...\")\n",
        "hmm_en = HiddenMarkovModelTagger.train(train_en)\n",
        "\n",
        "# 6. Evaluamos precisión\n",
        "acc_en = hmm_en.accuracy(test_en)\n",
        "\n",
        "# 7. Comparación final\n",
        "print(\"\\n--- COMPARATIVA DE IDIOMAS ---\")\n",
        "print(f\"Precisión en Español (CESS_ESP): {accuracy:.4f}\") # 'accuracy' viene del apartado b\n",
        "print(f\"Precisión en Inglés (Treebank): {acc_en:.4f}\")\n",
        "\n",
        "# 8. Ejemplo rápido en inglés\n",
        "frase_en = \"The cat is on the table\"\n",
        "tokens_en = nltk.word_tokenize(frase_en)\n",
        "print(f\"\\nEtiquetado ejemplo inglés: {hmm_en.tag(tokens_en)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7da9344-3aaa-4c68-bad1-22dad8a56974",
      "metadata": {
        "id": "b7da9344-3aaa-4c68-bad1-22dad8a56974"
      },
      "source": [
        "### f) Entrega este notebook completado (asegurate que funciona correctamente, y renombralo añadiendo tu nombre y apellidos al final) en la tarea de AULES de la unidad 3."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}